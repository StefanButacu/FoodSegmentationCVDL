{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from models.unet_from_scratch.UNET_MODEL_FROM_SCRATCH import UNET_FROM_SCRATCH\n",
    "from models.unet_from_scratch.utils import get_loaders, save_checkpoint, print_measurements, save_predictions_as_imgs, \\\n",
    "    load_checkpoint\n",
    "from models.unet_from_scratch.visual import DatasetViewer\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 7\n",
    "NUM_WORKERS = 2\n",
    "IMAGE_HEIGHT = 240\n",
    "IMAGE_WIDTH = 240\n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = False\n",
    "\n",
    "TRAIN_IMG_DIR = 'E:\\CVDL\\MyApp\\models\\data\\images'\n",
    "TRAIN_MASK_DIR = 'E:\\CVDL\\MyApp\\models\\data\\labels'\n",
    "VAL_IMG_DIR = 'E:\\CVDL\\MyApp\\models\\data\\\\validationimages'\n",
    "VAL_MASK_DIR = 'E:\\CVDL\\MyApp\\models\\data\\\\validationlabels'\n",
    "\n",
    "train_transfrom = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "        A.Rotate(limit=35, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.1),\n",
    "        A.Normalize(mean=[0.0, 0.0, 0.0],\n",
    "                    std=[1.0, 1.0, 1.0],\n",
    "                    max_pixel_value=255.0\n",
    "                    ),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transfrom = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "        A.Normalize(mean=[0.0, 0.0, 0.0],\n",
    "                    std=[1.0, 1.0, 1.0],\n",
    "                    max_pixel_value=255.0\n",
    "                    ),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_loaders(TRAIN_IMG_DIR,\n",
    "                                           TRAIN_MASK_DIR,\n",
    "                                           VAL_IMG_DIR,\n",
    "                                           VAL_MASK_DIR,\n",
    "                                           BATCH_SIZE,\n",
    "                                           train_transfrom,\n",
    "                                           val_transfrom,\n",
    "                                           NUM_WORKERS,\n",
    "                                           PIN_MEMORY\n",
    "                                           )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
    "    \"\"\"\n",
    "    :param loader:\n",
    "    :param model:\n",
    "    :param optimizer: - how the network will be updated based on the loss function\n",
    "    :param loss_fn: - quantity that will be minimized during training\n",
    "    :param scaler:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    loop = tqdm(loader)\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=DEVICE)\n",
    "        targets = targets.unsqueeze(1).to(device=DEVICE)\n",
    "        # forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(data)\n",
    "            loss = loss_fn(pred, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        loop.set_postfix(loss=loss.item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## UNET FROM SCRATCH\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\CVDL\\MyApp\\venv\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/94 [00:00<?, ?it/s]E:\\CVDL\\MyApp\\venv\\lib\\site-packages\\torch\\amp\\autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "100%|██████████| 94/94 [24:04<00:00, 15.37s/it, loss=0.415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>saving checkpoint to check_unet_scratch.pth.tar\n",
      "printing measure\n",
      "Got 70147379/86400000 with acc 81.19\n",
      "Got dice_score:0.8357783555984497 \n",
      "Got ioc1:0.41788917779922485 \n",
      "Epoch 2 / 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [23:56<00:00, 15.28s/it, loss=0.383]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>saving checkpoint to check_unet_scratch.pth.tar\n",
      "printing measure\n",
      "Got 71081699/86400000 with acc 82.27\n",
      "Got dice_score:0.8455772995948792 \n",
      "Got ioc1:0.4227886497974396 \n",
      "Epoch 3 / 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [23:54<00:00, 15.26s/it, loss=0.368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>saving checkpoint to check_unet_scratch.pth.tar\n",
      "printing measure\n",
      "Got 72207125/86400000 with acc 83.57\n",
      "Got dice_score:0.8583813905715942 \n",
      "Got ioc1:0.4291906952857971 \n",
      "Epoch 4 / 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [23:49<00:00, 15.20s/it, loss=0.351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>saving checkpoint to check_unet_scratch.pth.tar\n",
      "printing measure\n",
      "Got 72670187/86400000 with acc 84.11\n",
      "Got dice_score:0.8571197986602783 \n",
      "Got ioc1:0.42855989933013916 \n",
      "Epoch 5 / 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 35/94 [09:02<15:25, 15.68s/it, loss=0.34] "
     ]
    }
   ],
   "source": [
    "#########################\n",
    "model = UNET_FROM_SCRATCH(in_channels=3, out_channels=1).to(DEVICE)\n",
    "loss_fn = nn.BCEWithLogitsLoss()  # applies sigmoid on output\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch+1} / {NUM_EPOCHS}\")\n",
    "    train_fn(train_loader, model, optimizer, loss_fn, scaler)\n",
    "\n",
    "    # save model\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict()\n",
    "    }\n",
    "    save_checkpoint(checkpoint, 'check_unet_scratch.pth.tar')\n",
    "    print_measurements(train_loader, model, device=DEVICE)\n",
    "\n",
    "    # check acc\n",
    "    # print examples\n",
    "    if epoch == NUM_EPOCHS -1:\n",
    "        save_predictions_as_imgs(train_loader, model, folder=\"unet_from_scratch_saved_photos/\", device=DEVICE)\n",
    "\n",
    "print(\"End unet training\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validation UNET_FROM_SCRATCH"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "# from tqdm import tqdm\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from models.unet_from_scratch.utils import get_loaders, save_checkpoint, print_measurements, save_predictions_as_imgs, \\\n",
    "#     load_checkpoint\n",
    "#\n",
    "# LEARNING_RATE = 1e-4\n",
    "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# BATCH_SIZE = 16\n",
    "# NUM_EPOCHS = 10\n",
    "# NUM_WORKERS = 2\n",
    "# IMAGE_HEIGHT = 160\n",
    "# IMAGE_WIDTH = 240\n",
    "# PIN_MEMORY = True\n",
    "# LOAD_MODEL = True\n",
    "#\n",
    "# TRAIN_IMG_DIR = 'E:\\CVDL\\MyApp\\models\\data\\\\images'\n",
    "# TRAIN_MASK_DIR = 'E:\\CVDL\\MyApp\\models\\data\\labels'\n",
    "# VAL_IMG_DIR = 'E:\\CVDL\\MyApp\\models\\data\\\\validationimages'\n",
    "# VAL_MASK_DIR = 'E:\\CVDL\\MyApp\\models\\data\\\\validationlabels'\n",
    "#\n",
    "# train_transfrom = A.Compose(\n",
    "#     [\n",
    "#         A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "#         A.Rotate(limit=35, p=1.0),\n",
    "#         A.HorizontalFlip(p=0.5),\n",
    "#         A.VerticalFlip(p=0.1),\n",
    "#         A.Normalize(mean=[0.0, 0.0, 0.0],\n",
    "#                     std=[1.0, 1.0, 1.0],\n",
    "#                     max_pixel_value=255.0\n",
    "#                     ),\n",
    "#         ToTensorV2()\n",
    "#     ]\n",
    "# )\n",
    "#\n",
    "# val_transfrom = A.Compose(\n",
    "#     [\n",
    "#         A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "#         A.Normalize(mean=[0.0, 0.0, 0.0],\n",
    "#                     std=[1.0, 1.0, 1.0],\n",
    "#                     max_pixel_value=255.0\n",
    "#                     ),\n",
    "#         ToTensorV2()\n",
    "#     ]\n",
    "# )\n",
    "# train_loader, val_loader = get_loaders(TRAIN_IMG_DIR,\n",
    "#                                        TRAIN_MASK_DIR,\n",
    "#                                        VAL_IMG_DIR,\n",
    "#                                        VAL_MASK_DIR,\n",
    "#                                        BATCH_SIZE,\n",
    "#                                        train_transfrom,\n",
    "#                                        val_transfrom,\n",
    "#                                        NUM_WORKERS,\n",
    "#                                        PIN_MEMORY\n",
    "#                                        )\n",
    "#\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model_unet = UNET_FROM_SCRATCH(in_channels=3, out_channels=1).to(DEVICE)\n",
    "# if LOAD_MODEL:\n",
    "#     load_checkpoint(torch.load('check_unet_scratch.pth.tar'), model_unet)\n",
    "# print_measurements(val_loader, model_unet)\n",
    "# save_predictions_as_imgs(val_loader, model_unet, folder=\"validate_unet/\", device=DEVICE)\n",
    "#\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RESNET_UNET Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from models.unet_from_scratch.model import TrucnateResNET_UNET\n",
    "\n",
    "model = TrucnateResNET_UNET().to(DEVICE)\n",
    "loss_fn = nn.BCEWithLogitsLoss()  # applies sigmoid on output\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch+1} / {NUM_EPOCHS}\")\n",
    "    train_fn(train_loader, model, optimizer, loss_fn, scaler)\n",
    "\n",
    "    # save model\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict()\n",
    "    }\n",
    "    save_checkpoint(checkpoint, 'check_resnet_unet.pth.tar')\n",
    "    print_measurements(val_loader, model, device=DEVICE)\n",
    "\n",
    "    # check acc\n",
    "    # print examples\n",
    "    if epoch == NUM_EPOCHS -1:\n",
    "        save_predictions_as_imgs(val_loader, model, folder=\"unet_resnet_saved_photos/\", device=DEVICE)\n",
    "print(\"End resnet_unet training\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model_resnet_unet = TrucnateResNET_UNET().to(DEVICE)\n",
    "# if LOAD_MODEL:\n",
    "#     load_checkpoint(torch.load('check_resnet_unet.pth.tar'), model_resnet_unet)\n",
    "# print_measurements(val_loader, model_resnet_unet)\n",
    "# save_predictions_as_imgs(val_loader, model_resnet_unet, folder=\"validate_resnet/\", device=DEVICE)\n",
    "#\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
